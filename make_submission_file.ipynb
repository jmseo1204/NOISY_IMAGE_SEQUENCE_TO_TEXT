{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d034100-3318-40cc-9625-027a261e0056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\CafeAlle\\AppData\\Local\\Temp\\ipykernel_1356\\943707338.py\", line 12, in <module>\n",
      "    from new_modeling import * # You can import your custom model classes from modeling.py\n",
      "  File \"c:\\Users\\CafeAlle\\Desktop\\final\\new_modeling.py\", line 9, in <module>\n",
      "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "c:\\Users\\CafeAlle\\Desktop\\final\\new_modeling.py:9: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import MLDataset, collate_fn\n",
    "from new_modeling import * # You can import your custom model classes from modeling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "248fe8ee-1124-4cf1-818d-47998ef70b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd18fee5-3084-440d-b998-a60b2f174d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add or modify your Seq2SeqModel's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'hidden_dim': 256,\n",
    "    'n_rnn_layers': 1,\n",
    "    'rnn_dropout': 0.5,\n",
    "    'embedding_dim': 90\n",
    "\n",
    "    #teacherforcing ratio\n",
    "}\n",
    "kwargs_generate = {\n",
    "    # you can add arguments for your model's generate function\n",
    "    'max_length': 12\n",
    "}\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7751c02-3674-4616-a348-7e96c66f81d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqModelChallenge(\n",
      "  (encoder): Encoder(\n",
      "    (cnn): CustomCNN(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=1152, out_features=360, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=360, out_features=360, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=360, out_features=90, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (rnn): LSTM(90, 256, batch_first=True, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(28, 512, padding_idx=0)\n",
      "    (rnn): LSTM(1024, 512, batch_first=True, dropout=0.5)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (lm_head): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# You can use your own model class and model path\n",
    "\n",
    "model = Seq2SeqModelChallenge(num_classes=NUM_CLASSES, **kwargs).to(device)\n",
    "print(model)\n",
    "\n",
    "model_path = './challenge_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeffd8f0-96f0-4a62-b88f-06d1a1500cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [04:14<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created submission file successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Do not modify this cell!\n",
    "\n",
    "test_ds = MLDataset('data_final/imgs/test', 'data_final/labels/test_dummy.json')\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "state = torch.load(model_path)\n",
    "model.load_state_dict(state[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "ids = []\n",
    "predictions = []\n",
    "for batch_idx, (data, _, lengths) in enumerate(tqdm(test_dl)):       \n",
    "    data = data.to(device) # (B, T, H, W, C)\n",
    "    \n",
    "    # start tokens should be located at the first position of the decoder input\n",
    "    start_tokens = (torch.ones([data.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tok = model.generate(data, lengths, start_tokens, **kwargs_generate) # (B, T)\n",
    "\n",
    "    for i in range(generated_tok.size(0)):\n",
    "        sample_idx = batch_idx * BATCH_SIZE + i + 1\n",
    "        ids.append(sample_idx)\n",
    "        pred = 0\n",
    "        for j, tok in enumerate(generated_tok[i][:lengths[i].int()].tolist()):\n",
    "            pred += tok * math.pow(28, j)\n",
    "        predictions.append(int(pred))\n",
    "\n",
    "sub_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "print(\"Created submission file successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188835c4-ad1b-48b8-935b-2b5f4b44318f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
