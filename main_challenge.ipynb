{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf11d07-9856-42da-8125-3099f10e0669",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "Google drive mount (for Colab users) and package importing.\n",
    "You can optionally work on a transformer part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b82d731-fc8f-4681-8e8b-614b58e21bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_utils import MLDataset, collate_fn\n",
    "from modeling import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78120bd-5408-45b6-9ea1-ec1f080349ca",
   "metadata": {},
   "source": [
    "## (Optional) Sample Visualization\n",
    "You can see actual sample images and correct answers. Additional matplotlib package is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55336728-8e6c-4a3c-bf3d-b06e676b70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for reference: see actual samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "id_to_char = {}\n",
    "alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "for i, c in enumerate(alphabets):\n",
    "    id_to_char[i+1] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6f4666f-5a79-47aa-94f7-00c85f938460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: defines ([4, 5, 6, 9, 14, 5, 19])\n",
      "Input image sequence:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x700 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just for reference: see actual samples\n",
    "idx = 20000\n",
    "sample = np.load(f'./data_final/imgs/train/{idx}.npy')\n",
    "with open('./data_final/labels/train.json', 'r') as f:\n",
    "    sample_target = json.load(f)[str(idx)]\n",
    "    \n",
    "tgt_char = \"\"\n",
    "for i in sample_target:\n",
    "    tgt_char += id_to_char[i]\n",
    "\n",
    "\n",
    "print(f\"Answer: {tgt_char} ({sample_target})\")\n",
    "print(\"Input image sequence:\")\n",
    "\n",
    "plt.figure(figsize=(5, len(sample)))\n",
    "for i, img in enumerate(sample):    \n",
    "    plt.subplot(1, len(sample), i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400da0bd-7c64-4d23-a24b-b0d097d995ae",
   "metadata": {},
   "source": [
    "## Device and seed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4579ad2-6031-450c-a30c-cbf5b69fbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Use 0th GPU for training\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# fix random seed to increase reproducibility\n",
    "# NOTE: Do not modify here!\n",
    "NUM_CLASSES = 26 + 2 # 26 alphabets + 1 padding index + 1 <s> token (start token)\n",
    "\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "\n",
    "def seed_worker(worker_seed):\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6523c-962c-42fb-bbaa-38d8236797eb",
   "metadata": {},
   "source": [
    "## Model loading and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ffaa119-e2d5-4f4e-a663-5578c4f49359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: modify path and batch size for your setting\n",
    "# NOTE: you can apply custom preprocessing to the training data\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_ds = MLDataset('data_final/imgs/train', 'data_final/labels/train.json')\n",
    "#train_ds = MLDataset('data_final/imgs/train_challenge', 'data_final/labels/train_challenge.json')\n",
    "valid_ds = MLDataset('data_final/imgs/valid_normal', 'data_final/labels/valid_normal.json')\n",
    "challenge_ds = MLDataset('data_final/imgs/valid_challenge', 'data_final/labels/valid_challenge.json')\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "challenge_dl = DataLoader(challenge_ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77af1ae4-496f-4cbd-a2dc-9c429d052d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add or modify your Seq2SeqModel's hyperparameter (keys and values)\n",
    "kwargs = {\n",
    "    'hidden_dim': 256,\n",
    "    'n_rnn_layers': 1,\n",
    "    'rnn_dropout': 0.5,\n",
    "    'embedding_dim': 90\n",
    "\n",
    "    #teacherforcing ratio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "595dcc8b-006e-4730-94f6-933c2c743996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqModelChallenge(\n",
      "  (encoder): Encoder(\n",
      "    (cnn): CustomCNN(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (conv3): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=1152, out_features=360, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=360, out_features=360, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=360, out_features=90, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (rnn): LSTM(90, 256, batch_first=True, bidirectional=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(28, 512, padding_idx=0)\n",
      "    (rnn): LSTM(1024, 512, batch_first=True, dropout=0.5)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (lm_head): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqModelChallenge(num_classes=NUM_CLASSES, **kwargs).to(device)\n",
    "print(model)\n",
    "##############################################################################\n",
    "#                          IMPLEMENT YOUR CODE                               #\n",
    "##############################################################################\n",
    "model_optim = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)  # 0번 인덱스를 패딩으로 사용\n",
    "\n",
    "# Scheduler\n",
    "scheduler = StepLR(model_optim, step_size=1, gamma=0.9)\n",
    "# NOTE: you can define additional components like lr_scheduler, ...\n",
    "##############################################################################\n",
    "#                          END OF YOUR CODE                                  #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1cc52297-5653-4a17-8ec1-b529bb0e9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can freely modify or add training hyperparameters\n",
    "print_interval = 100\n",
    "max_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd18ddf1-a8d0-4ef6-a05f-ac4a38678b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path=None, save_path='./challenge_model.pt'):\n",
    "    ##############################################################################\n",
    "    #                          IMPLEMENT YOUR CODE                               #\n",
    "    ##############################################################################\n",
    "    # Load your states\n",
    "    loaded_epoch = 0\n",
    "    loaded_best_valid_loss = -1\n",
    "    if load_path is not None:\n",
    "        state = torch.load(load_path)\n",
    "        model.load_state_dict(state[\"model\"])\n",
    "        model_optim.load_state_dict(state[\"optimizer\"])\n",
    "        loaded_epoch = state[\"epoch\"]\n",
    "        loaded_best_valid_loss = state[\"best_valid_loss\"]\n",
    "        # ...\n",
    "\n",
    "    ##############################################################################\n",
    "    #                          END OF YOUR CODE                                  #\n",
    "    ##############################################################################\n",
    "    best_valid_loss = 1e+10 if loaded_best_valid_loss == -1 else loaded_best_valid_loss\n",
    "\n",
    "    losses = []\n",
    "    for epoch in np.array(list(range(max_epoch - loaded_epoch))) + loaded_epoch:\n",
    "        step = 0\n",
    "        train_loss = 0\n",
    "        print_loss = 0\n",
    "        model.train()\n",
    "        for batch_idx, (data, target, lengths) in enumerate(tqdm(train_dl)):\n",
    "            data = data.to(device) # (B, T, H, W, C)\n",
    "            target = target.to(device) # (B, T)\n",
    "\n",
    "            # start tokens should be located at the first position of the decoder input\n",
    "            start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)   #ind 0 is for <pad>, idx 27 is for <s>\n",
    "            ##############################################################################\n",
    "            #                          IMPLEMENT YOUR CODE                               #\n",
    "            ##############################################################################\n",
    "            # Problem 5: implement loss calculation and optimization part\n",
    "            # You can utilize teacher-forcing strategy to this part\n",
    "\n",
    "            model_optim.zero_grad()\n",
    "\n",
    "            # Prepare decoder input (start tokens + target without last token)\n",
    "            decoder_input = torch.cat([start_tokens, target[:, :-1]], dim=1) # is equal to input_sep in Decoder_forward\n",
    "            # Forward pass\n",
    "            output, _,  = model(data, lengths, decoder_input)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(output.permute(0, 2, 1), target)  # (B, N_vocab, T) -> (B, T, N_vocab) vs (B, T)\n",
    "            loss.backward()\n",
    "            model_optim.step()\n",
    "\n",
    "\n",
    "\n",
    "            ##############################################################################\n",
    "            #                          END OF YOUR CODE                                  #\n",
    "            ##############################################################################\n",
    "            train_loss += loss.detach().cpu().item()\n",
    "            step += 1\n",
    "            print_loss += loss.detach().cpu().item()\n",
    "            if (batch_idx + 1) % print_interval == 0:\n",
    "                print('epoch:', epoch + 1, 'step:', step + 1, 'loss:', print_loss/print_interval)\n",
    "                losses.append(print_loss/print_interval)\n",
    "                print_loss = 0\n",
    "\n",
    "        train_loss_avg = train_loss / (batch_idx+1)\n",
    "        print(f\"epoch {epoch + 1}, train loss: {train_loss_avg}\")\n",
    "\n",
    "        valid_loss = 0\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target, lengths) in enumerate(tqdm(valid_dl)):\n",
    "            with torch.no_grad():\n",
    "                data = data.to(device) # (B, T, H, W, C)\n",
    "                target = target.to(device) # (B, T)\n",
    "\n",
    "                # start tokens should be located at the first position of the decoder input\n",
    "                start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "                ##############################################################################\n",
    "                #                          IMPLEMENT YOUR CODE                               #\n",
    "                ##############################################################################\n",
    "                # Implement loss calculation for valid batch (same as problem 5)\n",
    "                decoder_input = torch.cat([start_tokens, target[:, :-1]], dim=1)\n",
    "\n",
    "                # Forward pass\n",
    "                output, _ = model(data, lengths, decoder_input)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = loss_fn(output.permute(0, 2, 1), target)  # (Batch_size, N_vocab, Sequence_length) vs (Batch_size, Sequence_length)\n",
    "                ##############################################################################\n",
    "                #                          END OF YOUR CODE                                  #\n",
    "                ##############################################################################\n",
    "                valid_loss += loss.cpu().item()\n",
    "        valid_loss /= (batch_idx + 1)\n",
    "        if valid_loss < best_valid_loss:\n",
    "            print(\"New best valid loss, saving model\")\n",
    "            ##############################################################################\n",
    "            #                          IMPLEMENT YOUR CODE                               #\n",
    "            ##############################################################################\n",
    "            # Save your states\n",
    "            state = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": model_optim.state_dict(),\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"best_valid_loss\": best_valid_loss,\n",
    "                # ...\n",
    "            }\n",
    "            ##############################################################################\n",
    "            #                          END OF YOUR CODE                                  #\n",
    "            ##############################################################################\n",
    "            torch.save(state, save_path)\n",
    "            best_valid_loss = valid_loss\n",
    "        print('valid epoch: %d, valid loss: %.4f, best valid loss: %.4f' % (epoch + 1, valid_loss, best_valid_loss))\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3803d7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:05<04:33,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 101 loss: 0.10118663184344769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:09<03:28,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 201 loss: 0.11083731785416603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:14<02:22,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 301 loss: 0.10201592691242695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:19<01:28,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 401 loss: 0.09827819310128688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:27<00:19,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 501 loss: 0.09066765807569027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [05:48<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 0.1001517969252026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:50<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 3, valid loss: 0.0950, best valid loss: 0.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<05:06,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 101 loss: 0.07738258175551892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:23<04:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 201 loss: 0.07426304552704095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:35<02:39,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 301 loss: 0.07475623115897179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:48<01:37,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 401 loss: 0.07445618692785501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:01<00:23,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 501 loss: 0.0723377650603652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:24<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.07452486652579236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 4, valid loss: 0.0783, best valid loss: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:07<04:43,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 101 loss: 0.058901411592960355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:14<03:38,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 201 loss: 0.06137229759246111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:22<02:51,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 301 loss: 0.06097464665770531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:29<01:30,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 401 loss: 0.06613647423684597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:38<00:21,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 501 loss: 0.06694642696529626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.06303543103560665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:52<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 5, valid loss: 0.0743, best valid loss: 0.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<05:01,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 101 loss: 0.050574523732066154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:24<03:48,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 201 loss: 0.05180594723671675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:38<03:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 301 loss: 0.052154898084700106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:51<01:33,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 401 loss: 0.05295808561146259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:06<00:23,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 501 loss: 0.05683508226647973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:29<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.05313127625754661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 6, valid loss: 0.0713, best valid loss: 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<05:08,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 101 loss: 0.04373526062816382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:24<03:57,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 201 loss: 0.04344182351604104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:38<02:58,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 301 loss: 0.04802253894507885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:53<01:32,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 401 loss: 0.04983061613515019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:08<00:23,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 501 loss: 0.051051747798919675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:31<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.047479625658014626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:52<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 7, valid loss: 0.0691, best valid loss: 0.0691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:12<05:11,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 101 loss: 0.040341222248971464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:24<03:59,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 201 loss: 0.044140906184911725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:37<02:37,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 301 loss: 0.043567284513264894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:49<01:33,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 401 loss: 0.04293338904157281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:03<00:24,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 501 loss: 0.04628497565165162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:27<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.04354583284345836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:54<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 8, valid loss: 0.0604, best valid loss: 0.0604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:12<05:12,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 101 loss: 0.03526668787002563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 140/531 [01:42<04:46,  1.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m load_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./challenge_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./challenge_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(kwargs)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses)\n",
      "Cell \u001b[1;32mIn[71], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path, save_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m print_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# (B, T, H, W, C)\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# (B, T)\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\Desktop\\final\\data_utils.py:21\u001b[0m, in \u001b[0;36mMLDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     18\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;28mstr\u001b[39m(idx)]\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong), seq_length\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load_path = './challenge_model.pt'\n",
    "losses = train(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path=load_path, save_path='./challenge_model.pt')\n",
    "print(kwargs)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfdbbb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/531 [00:00<?, ?it/s]c:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "c:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      " 19%|█▉        | 100/531 [01:09<05:08,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 101 loss: 1.9950614941120148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:17<03:28,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 201 loss: 1.1991788774728775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:26<02:49,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 301 loss: 0.7286568254232406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:35<01:29,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 401 loss: 0.4177131077647209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:42<00:20,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 501 loss: 0.2958542263507843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:03<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 0.8881923628448317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:51<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 1, valid loss: 0.2450, best valid loss: 0.2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:12<05:25,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 101 loss: 0.21669285655021667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:24<03:53,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 201 loss: 0.19808955892920493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:35<02:37,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 301 loss: 0.17664508149027824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:46<01:32,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 401 loss: 0.1609877137839794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:57<00:21,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 501 loss: 0.15133695475757122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:19<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 0.17870467424168202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 2, valid loss: 0.1465, best valid loss: 0.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:14<05:22,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 101 loss: 0.12422879047691822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:26<04:19,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 201 loss: 0.12136193268001079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:38<02:36,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 301 loss: 0.11833553284406662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:49<01:35,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 401 loss: 0.11256021924316884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:00<00:21,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 501 loss: 0.11212397739291191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:22<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 0.11724033167413848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 3, valid loss: 0.1143, best valid loss: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:13<05:08,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 101 loss: 0.09168079804629087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:25<03:48,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 201 loss: 0.09421482309699059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:37<02:42,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 301 loss: 0.09245381996035576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:48<01:36,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 401 loss: 0.0915981525182724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:01<00:21,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 501 loss: 0.08953540347516536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:23<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.09162810470088054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 4, valid loss: 0.0971, best valid loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<05:03,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 101 loss: 0.07289504636079074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:24<04:08,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 201 loss: 0.07324205748736859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:35<02:39,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 301 loss: 0.07466580763459206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:45<01:32,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 401 loss: 0.07234869226813316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:56<00:21,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 501 loss: 0.0738017788156867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:18<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.07348159053792612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 5, valid loss: 0.0907, best valid loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:10<05:11,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 101 loss: 0.059344519078731534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:20<03:49,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 201 loss: 0.06168021896854043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:31<02:43,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 301 loss: 0.061132054179906845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:43<01:34,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 401 loss: 0.06337939068675041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:54<00:22,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 501 loss: 0.06749340899288654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:17<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.06325058431738177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:54<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid epoch: 6, valid loss: 0.1296, best valid loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<05:09,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 101 loss: 0.05739087561145425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:23<03:43,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 201 loss: 0.05348238034173846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:35<02:47,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 301 loss: 0.05541173193603754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:47<01:34,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 401 loss: 0.05593657791614533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:58<00:22,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 501 loss: 0.05663578491657972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:19<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.055930561342201215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 7, valid loss: 0.0795, best valid loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<05:07,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 101 loss: 0.04376602310687303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:22<03:49,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 201 loss: 0.044841723367571834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:33<02:41,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 301 loss: 0.048083040975034234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:43<01:29,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 401 loss: 0.04923162169754505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [05:54<00:21,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 501 loss: 0.05259614922106266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:16<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.048181235818315134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:53<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 8, valid loss: 0.0756, best valid loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 100/531 [01:11<04:58,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 101 loss: 0.037979753827676176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 200/531 [02:22<03:51,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 201 loss: 0.04163299147039652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 300/531 [03:34<02:47,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 301 loss: 0.04643441017717123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 400/531 [04:48<01:36,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 401 loss: 0.0464785635843873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 500/531 [06:01<00:22,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 501 loss: 0.04739017516374588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [06:23<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.044397308754255876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:55<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best valid loss, saving model\n",
      "valid epoch: 9, valid loss: 0.0752, best valid loss: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/531 [00:05<06:44,  1.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m load_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_optim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./challenge_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path, save_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m print_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# (B, T, H, W, C)\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# (B, T)\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\Desktop\\final\\data_utils.py:17\u001b[0m, in \u001b[0;36mMLDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 17\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     seq_length \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;28mstr\u001b[39m(idx)]\n",
      "File \u001b[1;32mc:\\Users\\CafeAlle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:455\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    456\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "load_path = None\n",
    "train(model, model_optim, loss_fn, max_epoch, train_dl, valid_dl, load_path=load_path, save_path='./challenge_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83246b-de55-4668-bb78-c1fbb6c7f60d",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f3646f-f3a3-4d7f-b71c-9665f11450d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_generate = {\n",
    "    # you can add arguments for your model's generate function\n",
    "    'max_length': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce38064-e195-46c5-851c-43b116be5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell!\n",
    "\n",
    "def eval(dataloader, model_path):\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    id_to_char = {}\n",
    "    id_to_char[0] = \"<pad>\"\n",
    "    id_to_char[27] = \"<s>\"\n",
    "    alphabets = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "    for i, c in enumerate(alphabets):\n",
    "        id_to_char[i+1] = c\n",
    "\n",
    "    results = []\n",
    "    labels = []    \n",
    "    for batch_idx, (data, target, lengths) in enumerate(tqdm(dataloader)):       \n",
    "        data = data.to(device) # (B, T, H, W, C)\n",
    "        target = target.to(device) # (B, T)\n",
    "        \n",
    "        # start tokens should be located at the first position of the decoder input\n",
    "        start_tokens = (torch.ones([target.size(0), 1]) * 27).to(torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_tok = model.generate(data, lengths, start_tokens, **kwargs_generate) # (B, T)\n",
    "            \n",
    "        for i in range(generated_tok.size(0)):\n",
    "            decoded = \"\"\n",
    "            for j in generated_tok[i][:lengths[i].int()].tolist():\n",
    "                decoded += id_to_char[j]\n",
    "            results.append(decoded)\n",
    "    \n",
    "            decoded = \"\"\n",
    "            for j in target[i][:lengths[i].int()].tolist():\n",
    "                decoded += id_to_char[j]\n",
    "            labels.append(decoded)\n",
    "        \n",
    "    corrects = []\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == labels[i]:\n",
    "            corrects.append(1)\n",
    "        else:\n",
    "            corrects.append(0)\n",
    "    print(\"Accuracy: %.5f\" % (sum(corrects) / len(corrects)))\n",
    "\n",
    "    return results, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce11344-4b75-41a7-9701-9d372f840f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [04:21<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84467\n",
      "Evaluation with chllenge set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [03:58<00:00,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load and evaluate your model\n",
    "load_path = './challenge_model.pt'\n",
    "print(\"Evaluation with validation set\")\n",
    "results, labels = eval(valid_dl, load_path)\n",
    "\n",
    "print(\"Evaluation with chllenge set\")\n",
    "results, labels = eval(challenge_dl, load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4886a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이거 main_challenge.ipynb를 5epoch만 train한 것.\n",
    "#train할 때 loss 0.1이하로 떨어졌었음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
